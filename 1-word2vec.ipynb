{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Vol5bfrmSv1e"},"outputs":[],"source":["!pip install konlpy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A7VcdyoKR3ml"},"outputs":[],"source":["import xlrd\n","import openpyxl\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import urllib.request\n","import gensim\n","from gensim.models.word2vec import Word2Vec\n","from konlpy.tag import Okt\n","import os\n","\n","# Replace 'your_directory_path' with the path of your desired directory\n","directory_path = 'G:/academic/'\n","\n","# Change the working directory to the specified directory path\n","os.chdir(directory_path)\n","\n","# Verify that the working directory has been changed by printing the current directory\n","print(os.getcwd())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ko6oRp3VThNZ"},"outputs":[],"source":["# Replace 'your_excel_file.xlsx' with the name or path of your Excel file\n","file_path = 'data/data_name.xlsx'\n","\n","# Read the Excel file and load it into a DataFrame\n","df = pd.read_excel(file_path, engine='openpyxl')\n","\n","# Display the first few rows of the DataFrame\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MHDbFaamR5wZ"},"outputs":[],"source":["print(\"null exist:\", df.isnull().values.any()) # Null check\n","df = df.dropna(how = 'any') # Null delete\n","print(\"null exist(renew):\", df.isnull().values.any()) # Null re-check\n","print(\"number of title:\", len(df)) # counting sentense"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fSOTz2YuR5zp"},"outputs":[],"source":["# Remove non-Korean characters using regular expressions\n","df['title'] = df['title'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n","print(df[:5])    # 상위 5개 출력\n","\n","# Definition of stopwords\n","stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다','서','대다','로','에서','등','까지']\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LpITEgVpR527"},"outputs":[],"source":["# tokenizer OKT(Open Korean Text)\n","okt = Okt()\n","tokenized_data = []\n","for sentence in df['title']:\n","    temp_X = okt.morphs(sentence, stem=True) # tokenizing\n","    temp_X = [word for word in temp_X if not word in stopwords] # stopwords\n","    tokenized_data.append(temp_X)\n","print(tokenized_data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p-AFrkVFR56S"},"outputs":[],"source":["print('Max Length :',max(len(l) for l in tokenized_data))\n","print('Mean Length :',sum(map(len, tokenized_data))/len(tokenized_data))\n","plt.hist([len(s) for s in tokenized_data], bins=50)\n","plt.xlabel('Length of title')\n","plt.ylabel('Frequency')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W1cn8E-JR59d"},"outputs":[],"source":["#Word2Vec model\n","from gensim.models import Word2Vec\n","model = Word2Vec(sentences = tokenized_data, vector_size = 100, window = 10, min_count = 5, workers = 100, epochs=300, sg = 1) #sg=1 skipgram #vector_size or size # iter or epoch"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# embedded matrix\n","print(\"Embedded matrix:\", model.wv.vectors.shape)\n","print(model.wv.most_similar('위기', topn=10))   #top 10 results\n","model.wv.vectors"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from collections import Counter\n","\n","# Assuming you have a list of tokenized sentences called 'tokenized_data'\n","word_counts = Counter([word for sentence in tokenized_data for word in sentence])\n","\n","# Get the top 1000 most similar words to '위기'\n","wtw = model.wv.most_similar('위기', topn=1000)\n","\n","# Filter out words with length 1 and get their frequencies\n","wtw_words = [word for word, score in wtw if len(word) > 1]\n","wtw_scores = [score for word, score in wtw if len(word) > 1]\n","wtw_lengths = [len(word) for word, score in wtw if len(word) > 1]\n","wtw_frequencies = [word_counts[word] for word in wtw_words]\n","\n","# Create a DataFrame with the word, similarity score, length, and frequency columns\n","dfwtw = pd.DataFrame({'Word': wtw_words, 'Similarity Score': wtw_scores, 'Length': wtw_lengths, 'Frequency': wtw_frequencies})\n","\n","# Save the DataFrame to an Excel file\n","dfwtw.to_excel(\"neg_words_1000.xlsx\", index=False, engine=\"openpyxl\", encoding='utf-8')\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyP9E2X9H6TR2mLEjgkfXrtq","private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"},"vscode":{"interpreter":{"hash":"ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"}}},"nbformat":4,"nbformat_minor":0}
